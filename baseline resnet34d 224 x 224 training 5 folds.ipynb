{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 59093,
     "databundleVersionId": 7469972,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30636,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Created by yunsuxiaozi"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import necessary libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# https://www.kaggle.com/code/ttahara/hms-hbac-resnet34d-baseline-training\n",
    "# https://www.kaggle.com/code/ttahara/hms-hbac-resnet34d-baseline-inference\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class Config:\n",
    "    seed = 2024\n",
    "    image_transform = transforms.Resize((512, 512))\n",
    "    batch_size = 64\n",
    "    num_epochs = 10\n",
    "    num_folds = 5"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Seed "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def seed_everything(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "seed_everything(Config.seed)"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### labels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_df=pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "labels=['seizure','lpd','gpd','lrda','grda','other']\n",
    "for label in labels:\n",
    "    group=train_df[f'{label}_vote'].groupby(train_df['spectrogram_id']).sum()\n",
    "    label_vote_sum = pd.DataFrame({'spectrogram_id': group.index, f'{label}_vote_sum': group.values})\n",
    "    if label=='seizure':\n",
    "        train_feats=label_vote_sum\n",
    "    else:\n",
    "        train_feats=train_feats.merge(label_vote_sum,on='spectrogram_id',how='left')\n",
    "train_feats['total_vote']=0\n",
    "for label in labels:\n",
    "      train_feats['total_vote']+=train_feats[f'{label}_vote_sum']\n",
    "for label in labels:\n",
    "      train_feats[f'{label}_vote']=train_feats[f'{label}_vote_sum']/train_feats['total_vote']\n",
    "choose_cols=['spectrogram_id']\n",
    "for label in labels:\n",
    "    choose_cols+=[f'{label}_vote']\n",
    "train_feats=train_feats[choose_cols]\n",
    "train_feats['path'] = train_feats['spectrogram_id'].apply(lambda x: \"data/train_spectrograms/\" + str(x) + \".parquet\" )\n",
    "train_feats.head()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss function :Kullback Leibler Divergence"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def KL_loss(p,q):\n",
    "    epsilon=10**(-15)\n",
    "    p=torch.clip(p,epsilon,1-epsilon)\n",
    "    q = nn.functional.log_softmax(q,dim=1)\n",
    "    return torch.mean(torch.sum(p*(torch.log(p)-q),dim=1))"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get_batch_data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def get_batch(paths,batch_size=Config.batch_size):\n",
    "    eps=1e-6\n",
    "    batch_data=[]\n",
    "    for path in paths:\n",
    "        data=pd.read_parquet(path[0])\n",
    "        data = data.fillna(-1).values[:, 1:].T\n",
    "        data=data[:, 0:300]\n",
    "        data=np.clip(data, np.exp(-6), np.exp(10))\n",
    "        data= np.log(data)\n",
    "        data_mean=data.mean(axis=(0, 1))\n",
    "        data_std=data.std(axis=(0, 1))\n",
    "        data=(data - data_mean)/(data_std + eps)\n",
    "        data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n",
    "        data=Config.image_transform(data_tensor)\n",
    "        batch_data.append(data)\n",
    "    batch_data=torch.stack(batch_data)\n",
    "    return batch_data"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model_training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "device ='cuda' if  torch.cuda.is_available() else 'cpu'\n",
    "print(f\"device:{device}\")\n",
    "\n",
    "\n",
    "total_idx=np.arange(len(train_feats))\n",
    "np.random.shuffle(total_idx)\n",
    "\n",
    "for fold in range(Config.num_folds):\n",
    "\n",
    "    test_idx=total_idx[fold*len(total_idx)//Config.num_folds:(fold+1)*len(total_idx)//Config.num_folds]\n",
    "    train_idx=np.array([idx for idx in total_idx if idx not in test_idx])\n",
    "\n",
    "    model = timm.create_model('resnet34d',pretrained=True, num_classes=6, in_chans=1)\n",
    "    \n",
    "    optimizer=optim.AdamW(model.parameters(),lr=0.001,betas=(0.5,0.999),weight_decay=0.01)\n",
    "\n",
    "    best_test_loss=1.0\n",
    "    train_losses=[]\n",
    "    test_losses=[]\n",
    "\n",
    "    print(f\"start\")\n",
    "\n",
    "    for epoch in range(Config.num_epochs):\n",
    "        print(f\"epoch {epoch}:\")\n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        train_loss=[]\n",
    "        random_num=np.arange(len(train_idx))\n",
    "        np.random.shuffle(random_num)\n",
    "        train_idx=train_idx[random_num]\n",
    "\n",
    "        for idx in range(0,len(train_idx),Config.batch_size): \n",
    "            optimizer.zero_grad()\n",
    "            train_idx1=train_idx[idx:idx+Config.batch_size]\n",
    "            train_X1_path=train_feats[['path']].iloc[train_idx1].values\n",
    "            train_X1=get_batch(train_X1_path,batch_size=Config.batch_size)\n",
    "            train_y1=train_feats[['seizure_vote','lpd_vote','gpd_vote','lrda_vote','grda_vote','other_vote']].iloc[train_idx1].values\n",
    "            train_y1=torch.Tensor(train_y1)\n",
    "\n",
    "            train_pred=model(train_X1.to(device)).to(device)\n",
    "\n",
    "            loss=KL_loss(train_y1.to(device),train_pred.to(device)).to(device)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            print(f\"idx:{idx},loss:{loss}\")\n",
    "            train_loss.append(loss.detach().cpu().numpy())\n",
    "        train_loss=np.mean(np.array(train_loss))\n",
    "        print(f\"train_loss:{train_loss}\")\n",
    "        test_loss=[]\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx in range(0,len(test_idx),Config.batch_size): \n",
    "                test_idx1=test_idx[idx:idx+Config.batch_size]\n",
    "                test_X1_path=train_feats[['path']].iloc[test_idx1].values\n",
    "                test_X1=get_batch(test_X1_path,batch_size=Config.batch_size)\n",
    "\n",
    "                test_y1=train_feats[['seizure_vote','lpd_vote','gpd_vote','lrda_vote','grda_vote','other_vote']].iloc[test_idx1].values\n",
    "                test_y1=torch.Tensor(test_y1)\n",
    "\n",
    "                test_pred=model(test_X1.to(device)).to(device)\n",
    "\n",
    "                loss=KL_loss(test_y1.to(device),test_pred.to(device)).to(device)\n",
    "                test_loss.append(loss.detach().cpu().numpy())\n",
    "        test_loss=np.mean(np.array(test_loss))\n",
    "        print(f\"test_loss:{test_loss}\")\n",
    "        if test_loss<best_test_loss:\n",
    "            best_test_loss=test_loss\n",
    "            torch.save(model.to('cpu'),f\"HMS_resnet_fold{fold}.pth\")\n",
    "            \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        print(\"-\"*50)\n",
    "    print(f\"best_test_loss:{best_test_loss}\") \n",
    "    plt.title(\"train_losses VS test_losses\")\n",
    "    epochs=[i for i in range(len(train_losses))]\n",
    "    plt.plot(epochs,train_losses,marker=\"o\",markersize=1,label=\"train_losses\")\n",
    "    plt.plot(epochs,test_losses,marker=\"x\",markersize=1,label=\"test_losses\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
